#### XGBoost

- Vedere come si usa la best iteration
- Rendere generica la funzione che fa il test, ora usato per fare gli alberi xgboost
- Predict(pred_contrib) vedi cos’è 

https://stackoverflow.com/questions/43702514/how-to-get-each-individual-trees-prediction-in-xgboost

Significato dei valori in foglia
https://stats.stackexchange.com/questions/395697/what-is-an-intuitive-interpretation-of-the-leaf-values-in-xgboost-base-learners

C’è anche il problema delle features più usate
https://medium.com/towards-data-science/interpretable-machine-learning-with-xgboost-9ec80d148d27

Vedi plot_importance
https://github.com/nredell/ShapML.jl

#### Generali 

- Suite di machine learning H2O-3
- Estendere stratified cv a tutti i metodi

#### Importanza Massima

- rimuovere la dipendenza da Sole e aggiungere dipendenze da singoli pacchetti di Sole

- "DIfficile da fare": Unificare struttura dati feature selection con solexplorer: in features selection uso una matrice e un vettore di Xinfo.
  in realtà la struttura Dataset ha già una sorta di Xinfo dove salvo tutti i dati.

- passare a matrici?
  sicuramente salvare una matrice anzichè un dataframe è meglio, ma poi quando si va su MLJ dobbiamo tornare a DataFrame.
  da verificare con BenchmarkTools

- In prepare dataset, verificare se il dataset è bilanciato.
  se non lo, è da errore e suggerisce di lanciare prepare dataset con l'opzione balance=true.
  Se in prepare dataset fornisco l'opzione balance=true, che di default sarà false,
  esegue una funzione che verifica il numero di istanze del gruppo più piccolo,
  e prende quell'esatto numero di istanze (a random) dagli altri gruppi con maggiori istanze,
  restituendo un dataset bilanciato.

- verificare dove metter @threads
