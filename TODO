#### XGBoost

- Vedere come si usa la best iteration
- Rendere generica la funzione che fa il test, ora usato per fare gli alberi xgboost
- Predict(pred_contrib) vedi cos’è 

https://stackoverflow.com/questions/43702514/how-to-get-each-individual-trees-prediction-in-xgboost

Significato dei valori in foglia
https://stats.stackexchange.com/questions/395697/what-is-an-intuitive-interpretation-of-the-leaf-values-in-xgboost-base-learners

C’è anche il problema delle features più usate
https://medium.com/towards-data-science/interpretable-machine-learning-with-xgboost-9ec80d148d27

Vedi plot_importance
https://github.com/nredell/ShapML.jl

#### Generali 

- Suite di machine learning H2O-3

#### Importanza Massima

- esperimenti di regressione!

- "DIfficile da fare": Unificare struttura dati feature selection con solexplorer: in features selection uso una matrice e un vettore di Xinfo.
  in realtà la struttura Dataset ha già una sorta di Xinfo dove salvo tutti i dati.

- In prepare dataset, verificare se il dataset è bilanciato.
  https://github.com/JuliaAI/Imbalance.jl
  se non lo, è da errore e suggerisce di lanciare prepare dataset con l'opzione balance=true.
  Se in prepare dataset fornisco l'opzione balance=true, che di default sarà false,
  esegue una funzione che verifica il numero di istanze del gruppo più piccolo,
  e prende quell'esatto numero di istanze (a random) dagli altri gruppi con maggiori istanze,
  restituendo un dataset bilanciato.

- verificare dove metter @threads


### appunto
Matrix
@btime train_test(X, y; model=(type=:modaldecisiontree,))
400.538 ms (12649687 allocations: 498.99 MiB)
409.555 ms (12470188 allocations: 491.11 MiB)
416.705 ms (11877911 allocations: 467.46 MiB)
415.246 ms (12449374 allocations: 490.29 MiB)
429.349 ms (12142905 allocations: 478.51 MiB)

Dataframe
@btime traintest(X, y; models=(type=:modaldecisiontree,))
27.320 s (705005644 allocations: 31.04 GiB)
31.717 s (829947525 allocations: 36.61 GiB)
27.508 s (688818854 allocations: 30.31 GiB)

ma è possibile?
