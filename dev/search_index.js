var documenterSearchIndex = {"docs":
[{"location":"dataset/#setup-dataset","page":"Setup Dataset","title":"Setup dataset","text":"","category":"section"},{"location":"dataset/#dataset","page":"Setup Dataset","title":"Dataset","text":"","category":"section"},{"location":"dataset/#utilities","page":"Setup Dataset","title":"Utilities","text":"","category":"section"},{"location":"dataset/#train-test","page":"Setup Dataset","title":"Train and Test Dataset","text":"","category":"section"},{"location":"dataset/#SoleXplorer.setup_dataset-Tuple{DataFrames.AbstractDataFrame, Symbol}","page":"Setup Dataset","title":"SoleXplorer.setup_dataset","text":"setup_dataset(X::AbstractDataFrame, y::Symbol; kwargs...)::AbstractDataSet\n\nConvenience method when target variable is a column in the feature DataFrame.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.AbstractDataSet","page":"Setup Dataset","title":"SoleXplorer.AbstractDataSet","text":"AbstractDataSet\n\nAbstract supertype for all dataset structures in SoleXplorer.\n\nConcrete subtypes include:\n\nPropositionalDataSet: for standard ML algorithms with aggregated features\nModalDataSet: for modal logic algorithms with temporal structure preservation\n\n\n\n\n\n","category":"type"},{"location":"dataset/#SoleXplorer.AbstractSoleModel","page":"Setup Dataset","title":"SoleXplorer.AbstractSoleModel","text":"AbstractSoleModel\n\nBase abstract type for all symbolic model containers in SoleXplorer.\n\n\n\n\n\n","category":"type"},{"location":"dataset/#SoleXplorer.PropositionalDataSet","page":"Setup Dataset","title":"SoleXplorer.PropositionalDataSet","text":"PropositionalDataSet{M} <: AbstractDataSet\n\nDataset wrapper for standard machine learning algorithms that work with tabular/propositional data.\n\nThis dataset type encapsulates an MLJ machine along with partitioning information and optional aggregation metadata. It is used when working with traditional ML models that require flattened feature representations, typically created by aggregating multidimensional data.\n\nFields\n\nmach::MLJ.Machine: MLJ machine containing the model, training data, and cache\npidxs::Vector{PartitionIdxs}: Partition indices for train/test splits across folds\npinfo::PartitionInfo: Metadata about the partitioning strategy used\nainfo::MaybeAggregationInfo: Optional aggregation information for multidimensional data\n\nType Parameter\n\nM: The type of the MLJ model contained in the machine\n\nSee also: ModalDataSet, setup_dataset, AbstractDataSet\n\n\n\n\n\n","category":"type"},{"location":"dataset/#SoleXplorer.ModalDataSet","page":"Setup Dataset","title":"SoleXplorer.ModalDataSet","text":"ModalDataSet{M} <: AbstractDataSet\n\nDataset wrapper for modal logic algorithms that preserve temporal/structural relationships.\n\nThis dataset type is designed for modal learning algorithms that can work directly with multidimensional time series or structured data without requiring feature aggregation. It maintains treatment information that describes how the original data structure is preserved.\n\nFields\n\nmach::MLJ.Machine: MLJ machine containing the modal model, training data, and cache\npidxs::Vector{PartitionIdxs}: Partition indices for train/test splits across folds\npinfo::PartitionInfo: Metadata about the partitioning strategy used  \ntinfo::AbstractTreatmentInfo: Treatment information describing data structure preservation\n\nType Parameter\n\nM: The type of the modal MLJ model contained in the machine\n\nSee also: PropositionalDataSet, setup_dataset, AbstractDataSet\n\n\n\n\n\n","category":"type"},{"location":"dataset/#SoleXplorer.DataSet","page":"Setup Dataset","title":"SoleXplorer.DataSet","text":"DataSet(mach, pidxs, pinfo; tinfo=nothing) -> AbstractDataSet\n\nConstructor function that creates the appropriate dataset type based on treatment information.\n\nThis function serves as a smart constructor that automatically determines whether to create a PropositionalDataSet or ModalDataSet based on the provided treatment information and the type of treatment specified.\n\nArguments\n\nmach::MLJ.Machine{M}: MLJ machine containing model and data\npidxs::Vector{PartitionIdxs}: Partition indices for cross-validation folds\npinfo::PartitionInfo: Information about the partitioning strategy\ntinfo::MaybeTreatInfo=nothing: Optional treatment information for multidimensional data\n\nReturns\n\nPropositionalDataSet{M}: When tinfo is nothing or treatment is not :reducesize\nModalDataSet{M}: When tinfo specifies :reducesize treatment\n\nDecision Logic\n\nNo treatment info (tinfo = nothing): Creates PropositionalDataSet with no aggregation info\nReduce size treatment (get_treatment(tinfo) == :reducesize): Creates ModalDataSet preserving structure\nOther treatments (e.g., :aggregate): Creates PropositionalDataSet with aggregation info converted from treatment\n\nType Parameter\n\nM <: MLJ.Model: The type of the model in the MLJ machine\n\nSee also: PropositionalDataSet, ModalDataSet, AbstractDataSet\n\n\n\n\n\n","category":"function"},{"location":"dataset/#SoleXplorer.get_X-Tuple{AbstractDataSet}","page":"Setup Dataset","title":"SoleXplorer.get_X","text":"get_X(ds::AbstractDataSet) -> DataFrame\n\nExtract feature DataFrame from dataset's MLJ machine.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_X-Tuple{AbstractDataSet, Symbol}","page":"Setup Dataset","title":"SoleXplorer.get_X","text":"get_X(ds::AbstractDataSet, part::Symbol) -> Vector{<:AbstractDataFrame}\n\nExtract feature DataFrames for a specific partition (e.g., :train, :test or :valid) across all folds.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_y-Tuple{AbstractDataSet}","page":"Setup Dataset","title":"SoleXplorer.get_y","text":"get_y(ds::AbstractDataSet) -> Vector\n\nExtract target vector from dataset's MLJ machine.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_y-Tuple{AbstractDataSet, Symbol}","page":"Setup Dataset","title":"SoleXplorer.get_y","text":"get_y(ds::AbstractDataSet, part::Symbol) -> Vector{<:AbstractVector}\n\nExtract target values for a specific partition (e.g., :train, :test or :valid) across all folds.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_mach-Tuple{AbstractDataSet}","page":"Setup Dataset","title":"SoleXplorer.get_mach","text":"get_mach(ds::AbstractDataSet)::Machine\n\nExtract the MLJ machine from the dataset.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_mach_model-Tuple{AbstractDataSet}","page":"Setup Dataset","title":"SoleXplorer.get_mach_model","text":"get_mach_model(ds::AbstractDataSet)::MLJ.Model\n\nExtract the model from the dataset's MLJ machine.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.get_logiset-Tuple{ModalDataSet}","page":"Setup Dataset","title":"SoleXplorer.get_logiset","text":"get_logiset(ds::ModalDataSet)::SupportedLogiset\n\nExtract the logiset (if present) from the dataset's MLJ machine.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.code_dataset-Tuple{DataFrames.AbstractDataFrame}","page":"Setup Dataset","title":"SoleXplorer.code_dataset","text":"code_dataset(X::AbstractDataFrame)\n\nIn-place encoding of non-numeric columns in a DataFrame to numeric codes.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.code_dataset-Tuple{AbstractVector}","page":"Setup Dataset","title":"SoleXplorer.code_dataset","text":"code_dataset(y::AbstractVector)\n\nIn-place encoding of non-numeric target vector to numeric codes.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.code_dataset-Tuple{DataFrames.AbstractDataFrame, AbstractVector}","page":"Setup Dataset","title":"SoleXplorer.code_dataset","text":"code_dataset(X::AbstractDataFrame, y::AbstractVector)\n\nConvenience method to encode both features and target simultaneously.\n\n\n\n\n\n","category":"method"},{"location":"dataset/#SoleXplorer.train_test-Tuple{AbstractDataSet}","page":"Setup Dataset","title":"SoleXplorer.train_test","text":"train_test(ds::AbstractDataSet) -> SoleModel\n\nDirect training interface for pre-configured datasets. No additional parameters needed.\n\nSee also: symbolic_analysis, setup_dataset\n\n\n\n\n\n","category":"method"},{"location":"tuning/#tuning","page":"Tuning","title":"Tuning","text":"SoleXplorer uses the following tuning strategies adapted from package MLJ: GridTuning, RandomTuning, CubeTuning, ParticleTuning and AdaptiveTuning.\n\nstrategy_type::Type{<:Any}(;\n    range::RangeSpec,\n    MLJ.ResamplingStrategy=Holdout(fraction_train=0.7, shuffle=true),\n    measure::MaybeMeasure=nothing,\n    repeats::Int64=1,\n    strategy_kwargs...\n) -> Tuning","category":"section"},{"location":"tuning/#Arguments","page":"Tuning","title":"Arguments","text":"strategy_type: Type of optimization strategy to instantiate\nrange: Parameter ranges to explore\nresampling: Cross-validation for hyperparameter evaluation\nmeasure: Performance metric for optimization  \nrepeats: Number of optimization runs\nkwargs...: Strategy-specific parameters","category":"section"},{"location":"tuning/#tuning-strategies","page":"Tuning","title":"Tuning Strategies","text":"","category":"section"},{"location":"tuning/#range","page":"Tuning","title":"Tuning Range","text":"","category":"section"},{"location":"tuning/#SoleXplorer.GridTuning","page":"Tuning","title":"SoleXplorer.GridTuning","text":"GridTuning(; kwargs...) -> Tuning\n\nCreate a grid search tuning configuration. Parameters reference: MLJTuning.Grid\n\n\n\n\n\n","category":"function"},{"location":"tuning/#SoleXplorer.RandomTuning","page":"Tuning","title":"SoleXplorer.RandomTuning","text":"RandomTuning(; kwargs...) -> Tuning\n\nCreate a random search tuning configuration. Parameters reference: MLJTuning.RandomSearch\n\n\n\n\n\n","category":"function"},{"location":"tuning/#SoleXplorer.CubeTuning","page":"Tuning","title":"SoleXplorer.CubeTuning","text":"CubeTuning(; kwargs...) -> Tuning\n\nCreate a Latin hypercube sampling tuning configuration. Parameters reference: MLJTuning.LatinHypercube\n\n\n\n\n\n","category":"function"},{"location":"tuning/#SoleXplorer.ParticleTuning","page":"Tuning","title":"SoleXplorer.ParticleTuning","text":"ParticleTuning(; kwargs...) -> Tuning\n\nCreate a particle swarm optimization tuning configuration. Parameters reference: MLJParticleSwarmOptimization\n\n\n\n\n\n","category":"function"},{"location":"tuning/#SoleXplorer.AdaptiveTuning","page":"Tuning","title":"SoleXplorer.AdaptiveTuning","text":"AdaptiveTuning(; kwargs...) -> Tuning\n\nCreate an adaptive particle swarm optimization tuning configuration. Parameters reference: MLJParticleSwarmOptimization\n\n\n\n\n\n","category":"function"},{"location":"tuning/#Base.range","page":"Tuning","title":"Base.range","text":"range(field::Union{Symbol,Expr}; kwargs...)\n\nWrapper for MLJ.range in hyperparameter tuning contexts.\n\nArguments\n\nfield::Union{Symbol,Expr}: Model field to tune\nkwargs...: Range specification arguments\n\nReturns\n\nTuple of (field, kwargs) for later processing by tuning setup\n\nThis function provides a more convenient syntax for specifying hyperparameter ranges that will be converted to proper MLJ ranges once the model is available.\n\n\n\n\n\n","category":"function"},{"location":"serialize/#serialize","page":"Serialization","title":"Serialization","text":"SoleXplorer provides serialization functionality using the JLD2 format. It enables saving and loading of datasets, models, and analysis results with automatic file naming conventions and path management.","category":"section"},{"location":"serialize/#Supported-Types","page":"Serialization","title":"Supported Types","text":"All serialization functions work with types that implement the Saveable union:\n\nAbstractDataSet: Dataset configurations and ML pipelines\nAbstractSoleModel: Trained symbolic models  \nAbstractModelSet: Complete analysis results with multiple models","category":"section"},{"location":"serialize/#File-Format","page":"Serialization","title":"File Format","text":"All files are saved in JLD2 format with automatic .jld2 extension handling.","category":"section"},{"location":"serialize/#Naming-Convention","page":"Serialization","title":"Naming Convention","text":"Files are automatically prefixed based on content type:\n\nDatasets: soleds_<name>.jld2\nModels: solemodel_<name>.jld2 \nAnalysis: soleanalysis_<name>.jld2","category":"section"},{"location":"serialize/#Examples","page":"Serialization","title":"Examples","text":"using Test\nusing SoleXplorer\nusing MLJ\nusing DataFrames, Random\nconst SX = SoleXplorer\n\nXc, yc = @load_iris\nXc = DataFrame(Xc)\n\npath = @__DIR__\n\n# save dataset setup\nr1 = SX.range(:(oversampler.k), lower=3, upper=10)\nr2 = SX.range(:(undersampler.min_ratios), lower=0.1, upper=0.9)\n\ndsc = setup_dataset(\n    Xc, yc;\n    model=DecisionTreeClassifier(max_depth=3),\n    resampling=StratifiedCV(nfolds=5, shuffle=true),\n    seed=11,\n    balancing=(\n        oversampler=SMOTENC(k=5, ratios=1.0),\n        undersampler=TomekUndersampler(min_ratios=0.5)),\n    tuning=GridTuning(goal=4, range=(r1,r2))\n)\nsolesave(dsc; path, name=\"test1\")\n\nsolemc = train_test(dsc)\nsolesave(solemc; path, name=\"test1.jld2\")\n\nmodelc = symbolic_analysis(\n    dsc, solemc,\n    extractor=LumenRuleExtractor(minimization_scheme=:mitespresso),\n    measures=(accuracy, log_loss, kappa)\n)\nsolesave(modelc; path, name=\"test1\")\n\n# load dataset setup\nds_name        = \"soleds_test1\"\nsolemodel_name = \"solemodel_test1.jld2\"\nanalysis_name  = \"soleanalysis_test1\"\n\ndsc_loaded      = soleload(path, ds_name)\nmodel_loaded    = soleload(path, solemodel_name)\nanalysis_loaded = soleload(path, analysis_name)\n\nSee also: solesave, soleload \"\"\"","category":"section"},{"location":"serialize/#SoleXplorer.solesave","page":"Serialization","title":"SoleXplorer.solesave","text":"solesave(sole::Saveable; path::AbstractString, name::AbstractString)\n\nThis function handles the core serialization logic including file path construction, existence checking, and JLD2 serialization.\n\nArguments\n\nsole::Saveable: Object to serialize\npath::AbstractString: Directory path for saving (defaults to current directory)\nname::AbstractString: Base filename (automatically gets .jld2 extension)\n\nSee also: soleload\n\n\n\n\n\n","category":"function"},{"location":"serialize/#SoleXplorer.soleload","page":"Serialization","title":"SoleXplorer.soleload","text":"soleload(path::AbstractString, name::AbstractString) -> Saveable\n\nLoad a previously saved SoleXplorer object from disk.\n\nRestores datasets, models, or analysis results from JLD2 files created by solesave. The returned object type depends on what was originally saved.\n\nArguments\n\npath::AbstractString: Directory path containing the file\nname::AbstractString: Filename (with or without .jld2 extension)\n\nFile Extension\n\nAutomatically adds .jld2 extension if not provided in name.\n\nSee also: solesave\n\n\n\n\n\n","category":"function"},{"location":"symbolic_analysis/#symbolic-analysis","page":"Symbolic Analysis","title":"Symbolic analysis","text":"This is the entry point of SoleXplorer: this function can be used standalone, for finalize an already trained model, or to update already analyzed results.","category":"section"},{"location":"symbolic_analysis/#ModelSet","page":"Symbolic Analysis","title":"ModelSet","text":"","category":"section"},{"location":"symbolic_analysis/#SoleXplorer.symbolic_analysis-Tuple{DataFrames.AbstractDataFrame, AbstractVector, Union{Nothing, AbstractVector}}","page":"Symbolic Analysis","title":"SoleXplorer.symbolic_analysis","text":"symbolic_analysis(X::Any, args...; kwargs...) -> ModelSet\n\nConvenience method that converts input data to DataFrame format.\n\nSee also: symbolic_analysis\n\n\n\n\n\n","category":"method"},{"location":"symbolic_analysis/#SoleXplorer.symbolic_analysis-Tuple{AbstractDataSet, SoleXplorer.SoleModel}","page":"Symbolic Analysis","title":"SoleXplorer.symbolic_analysis","text":"symbolic_analysis(ds::AbstractDataSet, solem::SoleModel; kwargs...) -> ModelSet\n\nPerform complete symbolic analysis on pre-trained models.\n\nArguments\n\nds::AbstractDataSet: Dataset used for training the models.\nsolem::SoleModel: Trained sole symbolic models.\nkwargs...: Analysis options (extractor, association, measures).\n\nExamples\n\n# analyze pre-trained models\nds = setup_dataset(\n    X, y;\n    model=DecisionTreeClassifier(),\n    resampling=CV(nfolds=5, shuffle=true)\n)\nsolem = train_test(ds)\nresults = symbolic_analysis(\n    ds, solem; \n    extractor=Lumen(),\n    measures=(accuracy, kappa)\n)\n\nSee also: symbolic_analysis!, setup_dataset, train_test\n\n\n\n\n\n","category":"method"},{"location":"symbolic_analysis/#SoleXplorer.symbolic_analysis!-Tuple{ModelSet}","page":"Symbolic Analysis","title":"SoleXplorer.symbolic_analysis!","text":"symbolic_analysis!(modelset::ModelSet; kwargs...)\n\nPerform additional analysis on an existing ModelSet.\n\nIn-place version that adds or updates analysis components (rules, associations, measures) on an existing ModelSet.\n\nExamples\n\n# initial analysis\nmodelset = symbolic_analysis(X, y)\n\n# add rule extraction later\nsymbolic_analysis!(modelset; extractor=Lumen())\n\n# add association mining later\nsymbolic_analysis!(modelset; association=Apriori())\n\nSee also: symbolic_analysis, ModelSet\n\n\n\n\n\n","category":"method"},{"location":"treatement/#treatement","page":"Multi Dimensional Treatement","title":"Treatement","text":"With multidimensional datasets there are two possible types of work:\n\nUse of Propositional algorithms (DecisionTree, XGBoost):\nApplies windowing to divide time series into segments\nExtracts scalar features (max, min, mean, etc.) from each window\nReturns a standard tabular DataFrame\nUse of Modal algorithms (ModalDecisionTree):\nCreates windowed time series preserving temporal structure\nApplies reduction functions to manage dimensionality\n\n<!– Windowing strategies availables for reduce/aggregation time-series datasets.\n\n–>","category":"section"},{"location":"treatement/#featuresets","page":"Multi Dimensional Treatement","title":"Featuresets","text":"","category":"section"},{"location":"treatement/#Basic-Statistics","page":"Multi Dimensional Treatement","title":"Basic Statistics","text":"Standard statistical measures: maximum, minimum, mean, median, std, cov\n\n<!– ### Catch22 Features Canonical time-series characteristics covering:\n\nDistribution properties and extreme events\nLinear and nonlinear autocorrelation structures  \nForecasting performance and scaling properties\nSymbolic dynamics and transition patterns –>\n\n<!– ### Predefined Feature Sets\n\nbase_set: Minimal statistical features (4 features)\ncatch9: Curated subset combining statistics + key Catch22 (9 features)  \ncatch22_set: Complete Catch22 suite (22 features)\ncomplete_set: All features combined (28 features)","category":"section"},{"location":"treatement/#References","page":"Multi Dimensional Treatement","title":"References","text":"The Catch22 features are based on the Canonical Time-series Characteristics:\n\nRepository: https://github.com/DynamicsAndNeuralSystems/catch22\nPaper: Lubba, C.H., Sethi, S.S., Knaute, P. et al. \"catch22: CAnonical Time-series CHaracteristics.\" Data Min Knowl Disc 33, 1821–1852 (2019). https://doi.org/10.1007/s10618-019-00647-x –>\n\n<!– ```@docs baseset catch9 catch22set complete_set\n\n\nSee also: [`treatment`](@ref), [`setup_dataset`](@ref)\n\n## All Catch22 Features\n\n<!-- ```@docs\nmode_5\nmode_10  \nembedding_dist\nacf_timescale\nacf_first_min\nami2\ntrev\noutlier_timing_pos\noutlier_timing_neg\nwhiten_timescale\nforecast_error\nami_timescale\nhigh_fluctuation\nstretch_decreasing\nstretch_high\nentropy_pairs\nrs_range\ndfa\nlow_freq_power\ncentroid_freq\ntransition_variance\nperiodicity\n\n–>","category":"section"},{"location":"balancing/#balancing","page":"Balancing","title":"Balancing","text":"SoleXplorer uses the following balancing strategies taken from package Imbalance: \n\nBorderlineSMOTE1 ClusterUndersampler ENNUndersampler ROSE RandomOversampler RandomUndersampler RandomWalkOversampler SMOTE SMOTEN SMOTENC TomekUndersampler\n\nbalancing = (;\n    oversample=strategy(; kwargs...),\n    undersample=strategy(; kwargs...),\n) -> Balancing\n\nyou can also tune balancing strategy parameters using tuning and ranges, i.e:\n\nr1 = SX.range(:(oversampler.k), lower=3, upper=10)\nr2 = SX.range(:(undersampler.min_ratios), lower=0.1, upper=0.9)\nmodelc = symbolic_analysis(\n    Xc, yc;\n    model=RandomForestClassifier(),\n    resampling=StratifiedCV(nfolds=5, shuffle=true),\n    balancing=(\n        oversampler=SMOTENC(k=5, ratios=1.0),\n        undersampler=TomekUndersampler(min_ratios=0.5)),\n    tuning=GridTuning(goal=4, range=(r1,r2)),\n    measures=(accuracy, )\n)","category":"section"},{"location":"#SoleXplorer","page":"Home","title":"SoleXplorer","text":"","category":"section"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"Welcome to the documentation for SoleXplorer, an interactive interface for exploring symbolic machine learning models.\n\nBuilt on top of the Sole.jl ecosystem. It provides tools for visualizing, inspecting, and interacting with models derived from (logic-based) symbolic learning algorithms.\n\nKey features:\n\nCan handle both classification and regression tasks.\nInspect metrics.\nWorks also on time-series based datasets using modal logic.\nView rules and their metrics.\nInspect logical formulas and their evaluation.\n\n<!– * View modal rule associations. –> <!– * Integrated GUI. –>","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add SoleXplorer","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"#Decision-tree","page":"Home","title":"Decision tree","text":"Every parameter is defaulted: start analysis simply passing your raw dataset:\n\nusing SoleXplorer, MLJ\n\n# Load example dataset\nXc, yc = @load_iris\n\n# Train a decision tree\nmodelc = symbolic_analysis(Xc, yc)\n\nOf course, customizations are possible:\n\nusing Random\n\nrange = SoleXplorer.range(:min_purity_increase; lower=0.001, upper=1.0, scale=:log)\nmodelc = symbolic_analysis(\n    Xc, yc;\n    model=DecisionTreeClassifier(),\n    resampling=CV(nfolds=5, shuffle=true),\n    seed=1,\n    tuning=(tuning=Grid(resolution=10), resampling=CV(nfolds=3), range, measure=accuracy, repeats=2),\n    extractor=InTreesRuleExtractor(),\n    measures=(accuracy, log_loss, confusion_matrix, kappa)      \n)","category":"section"},{"location":"#Temporal-association-rules","page":"Home","title":"Temporal association rules","text":"# Load a temporal dataset\nnatopsloader = SoleXplorer.NatopsLoader()\nXts, yts = SoleXplorer.load(natopsloader)\n\n# Train a modal decision tree\nmodelts = symbolic_analysis(\n    Xts, yts;\n    model=ModalDecisionTree(),\n    resampling=Holdout(fraction_train=0.8, shuffle=true),\n    seed=1,\n    features=(minimum, maximum),\n    measures=(log_loss, accuracy, confusion_matrix, kappa)\n)","category":"section"},{"location":"#Related-packages","page":"Home","title":"Related packages","text":"SoleXplorer extensively uses the following packages:\n\nSoleLogics: modal and temporal logic systems.\nMLJ: provides all machine learning frameworks.\nSolePostHoc: for rule extraction.\n\n<!– * ModalAssociationRules: for mining association rules. –>","category":"section"},{"location":"#About","page":"Home","title":"About","text":"The package is developed by the ACLAI Lab @ University of Ferrara.","category":"section"}]
}
